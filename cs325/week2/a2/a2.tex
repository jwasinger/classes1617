\documentclass{article}
\usepackage{graphicx}
\usepackage{listings}

\begin{document}

\title{CS 325: Assignment 2}
\author{Jared Wasinger}

\maketitle

  \begin{enumerate}
    \item\begin{enumerate}
      \item $T(n) = T(n-2) + 2$\\
      Using the Muster Method:
      $a=1,b=2,d=0 (because f(n) = \Theta(1))$\\
      $T(n) = \Theta(n^{d+1}) = \Theta(n)$

      \item $T(n) = 3T(n-1) + 1$
      Using the Muster Method:
      $a=3,b=1,d=0 (because f(n) = \Theta(1)$
      $T(n) = \Theta(a^{n/b}) = \Theta(3^n)$

      \item $T(n) = 2T(n/4) + n^2$\\
      Master Method: $a=2, b=4, f(n)=n^2$\\
      $n^{log_ba} = n^{log42} = n^{0.5}$\\
      Case \#3: $T(n) = \Theta(n^2)$\\

      \item $T(n) = 9T(n/3) + 6n^2$\\
      Master Method: $a=9, b=3, f(n)=6n^2$\\
      $n^{log_ba} = n^{log_39} = n^2$
      Case \#2: $T(n) = \Theta(n^2lgn)$\\

    \end{enumerate}
    \item\begin{enumerate}
      \item Stooge sort works by recursively sorting the first $2/3$ of the input, sorting the last $2/3$ of the input and finally sorting the first $2/3$ again.\\
      This algorithm sorts the data because it is able to do a full sort (establish a global sorting fot the array) in three separate sorts.  The third sort is needed because the second sort may change ordering in a way that makes the results of the first sort on the beginning $1/3$ of the array no longer sorted
      \item No.  In the case where $n=4$, $k = floor(2n/3) = floor(2.\overline{6}) = 2$.  When the algorithm runs it will only sort the first and last half of the array making the result (possibly) incorrect.
      \item $T(n) = 3T(2n/3) + 1$
      \item Master Theorem:\\ 
        $a=3, f(n)=1, b=3/2$\\
        $n^{log_{3/2}3} \approx n^{2.71}$\\
        $f(n) = O(n^{2.71})$
    \end{enumerate}
    \item\begin{verbatim}
      def q_search(array, item):
        if len(array) == 3:
          return q_search(array[0]) || q_search(array[1] || q_search(array[2])
        elif len(array) == 2:
          return q_search(array[0]) || q_search(array[1]
        elif len(array) == 1:
          return array[0] == item

        first_quarter = len(array) / 4
        second_quarter = len(array) / 2
        third_quarter = (len(array) * 3) / 4

        #see if the value is in the first or second half
        if item <= array[second_quarter]:
          #determine if the value is in the first or second quartile
          if item > array[first_quarter]:
            return q_search(array[first_quarter+1:second_quarter]
          else:
            return q_search(array[0:first_quarter]))

        else:
          if item > array[third_quarter]:
            return q_search(array[third_quarter+1:len(array)])
          else:
            return q_search(array[second_quarter+1:third_quarter])
    \end{verbatim}
    \textbf{Recurrence relation for Quaternary Search:}\\
      $T(n) = T(n/4) + 2$\\
    Quaternary Search Asymptotic Complexity:\\
    \textbf{Master Method:}\\
    $a=1,b=4,f(n)=2$\\
    $f(n) = O(n^{log_41}) = O(1)$\\
    Therefore:\\
    $T(n) = \Theta(log_2n)$\\
    \textbf{Worst Case Performance Comparison:}\\
    The worst case performance of binary search is $O(logn)$.  The worst case performance of Quaternary Search is $\Theta(log_2n)$.  This tells us that, in the worst case, binary search will not perform slower than $logn$ whereas quaternary search is asymptotically equal to $log_2n$. ***

    \item\begin{verbatim}
      #return a tuple (max, min)
      def find_extremes(array):
        if len(array) == 1:
          return (array[0], array[0])
        elif len(array) == 2:
          return (max(array[0], array[1], min(array[0], array[1]))

        left_min_max = find_extremes(array[0:ceil(len(array)/2)])
        right_min_max = find_extremes(array[ceil(len(array)/2)+1:len(array)]

        return (max(left_min_max[0], right_min_max[0]), min(left_min_max[1], right_min_max[1]))

    \end{verbatim}
    \textbf{Recurrence Relationship:}\\
    $T(n) = 2T(n/2) + O(n)$
    \textbf{Asymptotic Complexity}\\
    Master Method\\
    $a = 2, b=2 f(n)=O(n)$\\
    $f(n) = O(n^{log_2{2}} = O(n)$\\
    Therefore\\
    $T(n) = \Theta(nlgn)$

    Because the iterative implementation of this algorithm is $\Theta(n)$, this means that the iterative implementation of the algorithm will scale better than the recursive one for large values of n.

    \item\begin{verbatim}
    def find_majority(array):
      if len(array) == 1:
        return (1, array[0])
      elif len(array) == 2:
        if array[0] == array[1]:
          return (2, array[0])
        else:
          return None
      else:
        majority_left = find_majority(array[0:ceil(len(array)/2)])
        majority_right = find_majority(array[ceil(len(array)/2)-1:len(array)])
        if !majority_left):
          return majority_right
        if !majority_right:
          return majority_left

        if majority_left[1] == majority_right[1]:
          return (majority_left[0] + majority_right[0], majority_right[1])
        else:
          else if majority_left[0] > majority_right[0]:
            return (majority_left[0] - majority_right[0], majority_left[1])
          else if majority_left[0] < majority_right[0]:
            return (majority_right[0] - majority_left[0], majority_right[1])
          else if majority_left[0] == majority_right[0]
            return None
    \end{verbatim}

    \textbf{Recurrence Relationship:}\\
    $T(n) = 2T(n/2) + O(n)$\\
    \textbf{Asymptotic Complexity}\\
    Master Method\\
    $a = 2, b=2 f(n)=O(n)$\\
    $f(n) = O(n^{log_2{2}} = O(n)$\\
    Therefore\\
    $T(n) = \Theta(nlgn)$

  \end{enumerate}
\end{document}
